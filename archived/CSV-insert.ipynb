{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4678ac3c-f28a-4ca9-a8b4-a15f1eccf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydbutils import make_connection, do_query_return_all, executeScriptsFromFile, read_config\n",
    "import csv\n",
    "import pymysql\n",
    "from sqlalchemy import URL, create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2089ae36-ede1-4473-a491-a0db47eca0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mysql.connector.connection.MySQLConnection at 0x27ca67f6190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = make_connection(config_file = 'superstore_test_db.ini', section = 'mysql', \n",
    "                       list_remove_from_config = ['drivername', 'database'])\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "741d09a8-4f5c-4751-9c3f-dd73a3e3c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03d0501e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://admin:***@database-1.cktdaj4eyk49.us-east-2.rds.amazonaws.com/superstore_test_db)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = read_config(config_file = 'superstore_test_db.ini', section = 'mysql')\n",
    "url_object = URL.create(**config)\n",
    "engine = create_engine(url_object)\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00b87d1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Unsupported argument 'drivername'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexecuteScriptsFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperstore_test_db.sql\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperstore_test_db.ini\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\MSDS\\git\\SuperstoreSales\\mydbutils.py:163\u001b[0m, in \u001b[0;36mexecuteScriptsFromFile\u001b[1;34m(filename, config_file)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecuteScriptsFromFile\u001b[39m(filename, config_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuperstore_db.ini\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    filename = \"superstore_db_schema.sql\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mmake_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Open and read the file as a single buffer\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\MSDS\\git\\SuperstoreSales\\mydbutils.py:30\u001b[0m, in \u001b[0;36mmake_connection\u001b[1;34m(config_file, section)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     db_config \u001b[38;5;241m=\u001b[39m read_config(config_file, section)\n\u001b[1;32m---> 30\u001b[0m     conn \u001b[38;5;241m=\u001b[39m MySQLConnection(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdb_config)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_connected():\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mysql\\connector\\connection.py:137\u001b[0m, in \u001b[0;36mMySQLConnection.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;66;03m# Tidy-up underlying socket on failure\u001b[39;00m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mysql\\connector\\abstracts.py:1092\u001b[0m, in \u001b[0;36mMySQLConnectionAbstract.connect\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124;03m\"\"\"Connect to the MySQL server\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m \n\u001b[0;32m   1087\u001b[0m \u001b[38;5;124;03mThis method sets up the connection to the MySQL server. If no\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;124;03marguments are given, it will use the already configured or default\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;124;03mvalues.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m-> 1092\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisconnect()\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_connection()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mysql\\connector\\abstracts.py:582\u001b[0m, in \u001b[0;36mMySQLConnectionAbstract.config\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     DEFAULT_CONFIGURATION[key]\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 582\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;66;03m# SSL Configuration\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: Unsupported argument 'drivername'"
     ]
    }
   ],
   "source": [
    "executeScriptsFromFile('superstore_test_db.sql','superstore_test_db.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6afaf34f-29d8-4685-9369-4004f56416f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    row_id         OrderID  OrderDate   ShipDate        ShipMode CustomerID  \\\n",
      "0        1  CA-2017-152156 2017-08-11 2017-11-11    Second Class   CG-12520   \n",
      "1        2  CA-2017-152156 2017-08-11 2017-11-11    Second Class   CG-12520   \n",
      "2        3  CA-2017-138688 2017-12-06 2017-06-16    Second Class   DV-13045   \n",
      "3        4  US-2016-108966 2016-11-10 2016-10-18  Standard Class   SO-20335   \n",
      "4        5  US-2016-108966 2016-11-10 2016-10-18  Standard Class   SO-20335   \n",
      "..     ...             ...        ...        ...             ...        ...   \n",
      "94      95  CA-2016-149587 2016-01-31 2016-05-02    Second Class   KB-16315   \n",
      "95      96  US-2018-109484 2018-06-11 2018-12-11  Standard Class   RB-19705   \n",
      "96      97  CA-2018-161018 2018-09-11 2018-11-11    Second Class   PN-18775   \n",
      "97      98  CA-2018-157833 2018-06-17 2018-06-20     First Class   KD-16345   \n",
      "98      99  CA-2017-149223 2017-06-09 2017-11-09  Standard Class   ER-13855   \n",
      "\n",
      "         CustomerName      Segment        Country             City  \\\n",
      "0         Claire Gute     Consumer  United States        Henderson   \n",
      "1         Claire Gute     Consumer  United States        Henderson   \n",
      "2     Darrin Van Huff    Corporate  United States      Los Angeles   \n",
      "3      Sean O'Donnell     Consumer  United States  Fort Lauderdale   \n",
      "4      Sean O'Donnell     Consumer  United States  Fort Lauderdale   \n",
      "..                ...          ...            ...              ...   \n",
      "94         Karl Braun     Consumer  United States      Minneapolis   \n",
      "95       Roger Barcio  Home Office  United States         Portland   \n",
      "96     Parhena Norris  Home Office  United States    New York City   \n",
      "97   Katherine Ducich     Consumer  United States    San Francisco   \n",
      "98  Elpida Rittenbach    Corporate  United States       Saint Paul   \n",
      "\n",
      "         State  PostalCode   Region        ProductID         Category  \\\n",
      "0     Kentucky       42420    South  FUR-BO-10001798        Furniture   \n",
      "1     Kentucky       42420    South  FUR-CH-10000454        Furniture   \n",
      "2   California       90036     West  OFF-LA-10000240  Office Supplies   \n",
      "3      Florida       33311    South  FUR-TA-10000577        Furniture   \n",
      "4      Florida       33311    South  OFF-ST-10000760  Office Supplies   \n",
      "..         ...         ...      ...              ...              ...   \n",
      "94   Minnesota       55407  Central  OFF-BI-10002852  Office Supplies   \n",
      "95      Oregon       97206     West  OFF-BI-10004738  Office Supplies   \n",
      "96    New York       10009     East  FUR-FU-10000629        Furniture   \n",
      "97  California       94122     West  OFF-BI-10001721  Office Supplies   \n",
      "98   Minnesota       55106  Central  OFF-AP-10000358  Office Supplies   \n",
      "\n",
      "    SubCategory                                        ProductName     Sales  \\\n",
      "0     Bookcases                  Bush Somerset Collection Bookcase  261.9600   \n",
      "1        Chairs  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400   \n",
      "2        Labels  Self-Adhesive Address Labels for Typewriters b...   14.6200   \n",
      "3        Tables      Bretford CR4500 Series Slim Rectangular Table  957.5775   \n",
      "4       Storage                     Eldon Fold 'N Roll Cart System   22.3680   \n",
      "..          ...                                                ...       ...   \n",
      "94      Binders                  Ibico Standard Transparent Covers   32.9600   \n",
      "95      Binders  Flexible Leather- Look Classic Collection Ring...    5.6820   \n",
      "96  Furnishings                    9-3/4 Diameter Round Wall Clock   96.5300   \n",
      "97      Binders                     Trimflex Flexible Post Binders   51.3120   \n",
      "98   Appliances  Fellowes Basic Home/Office Series Surge Protec...   77.8800   \n",
      "\n",
      "    FirstName    LastName  \n",
      "0      Claire        Gute  \n",
      "1      Claire        Gute  \n",
      "2      Darrin         Van  \n",
      "3        Sean   O'Donnell  \n",
      "4        Sean   O'Donnell  \n",
      "..        ...         ...  \n",
      "94       Karl       Braun  \n",
      "95      Roger      Barcio  \n",
      "96    Parhena      Norris  \n",
      "97  Katherine      Ducich  \n",
      "98     Elpida  Rittenbach  \n",
      "\n",
      "[99 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/12/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/11/2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/10/2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read csv, define col names\n",
    "data = pd.read_csv(\"train.csv\", skiprows=1, names=['row_id', 'OrderID','OrderDate','ShipDate','ShipMode','CustomerID','CustomerName','Segment','Country','City','State','PostalCode','Region','ProductID','Category','SubCategory','ProductName','Sales'])\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Convert the date columns to date format\n",
    "data[\"OrderDate\"] = pd.to_datetime(data[\"OrderDate\"])\n",
    "data[\"ShipDate\"] = pd.to_datetime(data[\"ShipDate\"])\n",
    "# split the Name column into two columns\n",
    "data['FirstName'] = data.CustomerName.str.split(' ', expand = True)[0]\n",
    "data['LastName'] = data.CustomerName.str.split(' ', expand = True)[1]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec522c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Customers table\n",
    "df_customers = data.loc[:,['CustomerID','FirstName','LastName','Segment','Country','City','State','PostalCode','Region']]\n",
    "df_customers = df_customers.drop_duplicates(subset='CustomerID', keep=\"first\")\n",
    "df_customers.to_sql(name='customers', con = engine, if_exists = 'append',index = False, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9827f095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Category table\n",
    "df_category = data.loc[:,['Category','SubCategory']]\n",
    "df_category = df_category.drop_duplicates(subset=['Category', 'SubCategory'], keep=\"first\")\n",
    "df_category = df_category.sort_values(by=['Category','SubCategory'])\n",
    "df_category['CategoryID'] = range(1, len(df_category) + 1)\n",
    "# print(df_category)\n",
    "df_category.to_sql(name='category', con = engine, if_exists = 'append',index = False, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153becf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Products table\n",
    "df_products = data.loc[:,['ProductID','Category','SubCategory','ProductName']]\n",
    "df_products = df_products.drop_duplicates(subset=['ProductID'], keep=\"first\")\n",
    "df_products = df_products.merge(df_category, how = 'left', on = ['Category', 'SubCategory'])\n",
    "df_products = df_products.drop(['Category','SubCategory'], axis=1)\n",
    "# print(df_products)\n",
    "df_products.to_sql(name='products', con = engine, if_exists = 'append',index = False, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7776aa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Orders table\n",
    "df_orders = data.loc[:,['OrderID','OrderDate','ShipDate','ShipMode','CustomerID']]\n",
    "df_orders = df_orders.drop_duplicates(subset=['OrderID'], keep=\"first\")\n",
    "df_orders.to_sql(name='orders', con = engine, if_exists = 'append',index = False, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22c9e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Sales table\n",
    "df_sales = data.loc[:,['OrderID','ProductID','Sales']]\n",
    "df_sales = df_sales.drop_duplicates(subset=['OrderID','ProductID'], keep=\"first\")\n",
    "df_sales.to_sql(name='sales', con = engine, if_exists = 'append',index = False, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a5f42a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2015-105893</td>\n",
       "      <td>OFF-ST-10004186</td>\n",
       "      <td>665.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2015-106376</td>\n",
       "      <td>OFF-AR-10002671</td>\n",
       "      <td>1113.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2015-106376</td>\n",
       "      <td>TEC-PH-10002726</td>\n",
       "      <td>167.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2015-115812</td>\n",
       "      <td>FUR-FU-10001487</td>\n",
       "      <td>48.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2015-115812</td>\n",
       "      <td>FUR-TA-10001539</td>\n",
       "      <td>1706.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>US-2018-118038</td>\n",
       "      <td>FUR-FU-10000260</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>US-2018-118038</td>\n",
       "      <td>OFF-BI-10004182</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>US-2018-118038</td>\n",
       "      <td>OFF-ST-10000615</td>\n",
       "      <td>27.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>US-2018-119662</td>\n",
       "      <td>OFF-ST-10003656</td>\n",
       "      <td>230.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>US-2018-156909</td>\n",
       "      <td>FUR-CH-10002774</td>\n",
       "      <td>71.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           OrderID        ProductID    Sales\n",
       "0   CA-2015-105893  OFF-ST-10004186   665.88\n",
       "1   CA-2015-106376  OFF-AR-10002671  1113.02\n",
       "2   CA-2015-106376  TEC-PH-10002726   167.97\n",
       "3   CA-2015-115812  FUR-FU-10001487    48.86\n",
       "4   CA-2015-115812  FUR-TA-10001539  1706.18\n",
       "..             ...              ...      ...\n",
       "94  US-2018-118038  FUR-FU-10000260     9.71\n",
       "95  US-2018-118038  OFF-BI-10004182     1.25\n",
       "96  US-2018-118038  OFF-ST-10000615    27.24\n",
       "97  US-2018-119662  OFF-ST-10003656   230.38\n",
       "98  US-2018-156909  FUR-CH-10002774    71.37\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sales = pd.read_sql_query('Select * from sales;', conn)\n",
    "data_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
